{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bac47-ddaf-449e-b2c0-3ff13f21daad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    " \n",
    "with zipfile.ZipFile('/home/jupyter/datasphere/project/archive_food.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3485cf8b-d9c7-44d9-8a4a-01400343262c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T20:51:49.942904Z",
     "iopub.status.busy": "2024-06-06T20:51:49.941534Z",
     "iopub.status.idle": "2024-06-06T20:51:58.145050Z",
     "shell.execute_reply": "2024-06-06T20:51:58.143705Z",
     "shell.execute_reply.started": "2024-06-06T20:51:49.942856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb971fd-7749-4bff-82a0-1353f8b740db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T20:51:58.149202Z",
     "iopub.status.busy": "2024-06-06T20:51:58.147628Z",
     "iopub.status.idle": "2024-06-06T20:51:58.174173Z",
     "shell.execute_reply": "2024-06-06T20:51:58.173032Z",
     "shell.execute_reply.started": "2024-06-06T20:51:58.149145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4fdd6dc-b097-4d1b-b577-de6486b92c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T21:32:34.383769Z",
     "iopub.status.busy": "2024-06-06T21:32:34.382793Z",
     "iopub.status.idle": "2024-06-06T21:32:36.246880Z",
     "shell.execute_reply": "2024-06-06T21:32:36.245542Z",
     "shell.execute_reply.started": "2024-06-06T21:32:34.383718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create the dataset class\n",
    "class Food101(Dataset):\n",
    "    def __init__(self, dataframe, base_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_dir, self.dataframe.path.iloc[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.label.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "images_dir = 'archive_food/images/'\n",
    "\n",
    "dataframe = []\n",
    "for root, _, files in os.walk(images_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "            file_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root)\n",
    "            formatted_path = os.path.join(label, file)\n",
    "            dataframe.append({'path': formatted_path, 'label': label})\n",
    "\n",
    "dataframe = pd.DataFrame(dataframe)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "food_dataset = Food101(dataframe, images_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.7 * len(food_dataset))\n",
    "val_size = int(0.15 * len(food_dataset))\n",
    "test_size = len(food_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(food_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet101 = resnet101(pretrained=True)\n",
    "        for param in self.resnet101.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet101.fc = nn.Linear(self.resnet101.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet101(x)\n",
    "        return x\n",
    "\n",
    "model = ResNetClassifier(num_classes=len(food_dataset.dataframe['label'].unique())).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a06a13c-1c24-44f6-89f6-ba00ebf85583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T21:32:36.493979Z",
     "iopub.status.busy": "2024-06-06T21:32:36.492711Z",
     "iopub.status.idle": "2024-06-06T21:32:36.518772Z",
     "shell.execute_reply": "2024-06-06T21:32:36.517638Z",
     "shell.execute_reply.started": "2024-06-06T21:32:36.493926Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           path         label\n",
      "0         foie_gras/1244707.jpg     foie_gras\n",
      "1         foie_gras/1335868.jpg     foie_gras\n",
      "2         foie_gras/1176321.jpg     foie_gras\n",
      "3         foie_gras/1421924.jpg     foie_gras\n",
      "4         foie_gras/1051563.jpg     foie_gras\n",
      "...                         ...           ...\n",
      "20195  caesar_salad/1397383.jpg  caesar_salad\n",
      "20196   caesar_salad/126205.jpg  caesar_salad\n",
      "20197  caesar_salad/1517451.jpg  caesar_salad\n",
      "20198    caesar_salad/15081.jpg  caesar_salad\n",
      "20199  caesar_salad/1351688.jpg  caesar_salad\n",
      "\n",
      "[20200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87a47799-ae80-4a24-a8b0-c809b15c7bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T21:32:38.416217Z",
     "iopub.status.busy": "2024-06-06T21:32:38.415015Z",
     "iopub.status.idle": "2024-06-06T22:26:30.906287Z",
     "shell.execute_reply": "2024-06-06T22:26:30.904882Z",
     "shell.execute_reply.started": "2024-06-06T21:32:38.416161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/14140 (0%)]\tLoss: 4.673238\n",
      "Train Epoch: 0 [640/14140 (5%)]\tLoss: 4.556993\n",
      "Train Epoch: 0 [1280/14140 (9%)]\tLoss: 4.447625\n",
      "Train Epoch: 0 [1920/14140 (14%)]\tLoss: 3.972295\n",
      "Train Epoch: 0 [2560/14140 (18%)]\tLoss: 4.136531\n",
      "Train Epoch: 0 [3200/14140 (23%)]\tLoss: 3.443301\n",
      "Train Epoch: 0 [3840/14140 (27%)]\tLoss: 3.513201\n",
      "Train Epoch: 0 [4480/14140 (32%)]\tLoss: 3.432453\n",
      "Train Epoch: 0 [5120/14140 (36%)]\tLoss: 3.115723\n",
      "Train Epoch: 0 [5760/14140 (41%)]\tLoss: 3.122023\n",
      "Train Epoch: 0 [6400/14140 (45%)]\tLoss: 3.158931\n",
      "Train Epoch: 0 [7040/14140 (50%)]\tLoss: 2.724830\n",
      "Train Epoch: 0 [7680/14140 (54%)]\tLoss: 3.081381\n",
      "Train Epoch: 0 [8320/14140 (59%)]\tLoss: 2.841461\n",
      "Train Epoch: 0 [8960/14140 (63%)]\tLoss: 2.470081\n",
      "Train Epoch: 0 [9600/14140 (68%)]\tLoss: 2.986862\n",
      "Train Epoch: 0 [10240/14140 (72%)]\tLoss: 2.714617\n",
      "Train Epoch: 0 [10880/14140 (77%)]\tLoss: 2.843295\n",
      "Train Epoch: 0 [11520/14140 (81%)]\tLoss: 2.484378\n",
      "Train Epoch: 0 [12160/14140 (86%)]\tLoss: 2.367414\n",
      "Train Epoch: 0 [12800/14140 (90%)]\tLoss: 2.588094\n",
      "Train Epoch: 0 [13440/14140 (95%)]\tLoss: 2.271448\n",
      "Train Epoch: 0 [13200/14140 (100%)]\tLoss: 2.512040\n",
      "Validation Accuracy: 0.4063\n",
      "Train Epoch: 1 [0/14140 (0%)]\tLoss: 2.472453\n",
      "Train Epoch: 1 [640/14140 (5%)]\tLoss: 2.066810\n",
      "Train Epoch: 1 [1280/14140 (9%)]\tLoss: 2.133908\n",
      "Train Epoch: 1 [1920/14140 (14%)]\tLoss: 2.282056\n",
      "Train Epoch: 1 [2560/14140 (18%)]\tLoss: 2.478972\n",
      "Train Epoch: 1 [3200/14140 (23%)]\tLoss: 2.227258\n",
      "Train Epoch: 1 [3840/14140 (27%)]\tLoss: 1.936604\n",
      "Train Epoch: 1 [4480/14140 (32%)]\tLoss: 2.362154\n",
      "Train Epoch: 1 [5120/14140 (36%)]\tLoss: 2.359127\n",
      "Train Epoch: 1 [5760/14140 (41%)]\tLoss: 2.177154\n",
      "Train Epoch: 1 [6400/14140 (45%)]\tLoss: 1.778849\n",
      "Train Epoch: 1 [7040/14140 (50%)]\tLoss: 2.271769\n",
      "Train Epoch: 1 [7680/14140 (54%)]\tLoss: 2.003043\n",
      "Train Epoch: 1 [8320/14140 (59%)]\tLoss: 2.096131\n",
      "Train Epoch: 1 [8960/14140 (63%)]\tLoss: 1.886840\n",
      "Train Epoch: 1 [9600/14140 (68%)]\tLoss: 1.951887\n",
      "Train Epoch: 1 [10240/14140 (72%)]\tLoss: 1.825003\n",
      "Train Epoch: 1 [10880/14140 (77%)]\tLoss: 2.334180\n",
      "Train Epoch: 1 [11520/14140 (81%)]\tLoss: 2.032761\n",
      "Train Epoch: 1 [12160/14140 (86%)]\tLoss: 2.078827\n",
      "Train Epoch: 1 [12800/14140 (90%)]\tLoss: 2.214736\n",
      "Train Epoch: 1 [13440/14140 (95%)]\tLoss: 1.888732\n",
      "Train Epoch: 1 [13200/14140 (100%)]\tLoss: 1.764744\n",
      "Validation Accuracy: 0.4495\n",
      "Train Epoch: 2 [0/14140 (0%)]\tLoss: 1.605954\n",
      "Train Epoch: 2 [640/14140 (5%)]\tLoss: 2.127031\n",
      "Train Epoch: 2 [1280/14140 (9%)]\tLoss: 1.955188\n",
      "Train Epoch: 2 [1920/14140 (14%)]\tLoss: 1.614778\n",
      "Train Epoch: 2 [2560/14140 (18%)]\tLoss: 1.724648\n",
      "Train Epoch: 2 [3200/14140 (23%)]\tLoss: 1.681069\n",
      "Train Epoch: 2 [3840/14140 (27%)]\tLoss: 1.576917\n",
      "Train Epoch: 2 [4480/14140 (32%)]\tLoss: 1.699059\n",
      "Train Epoch: 2 [5120/14140 (36%)]\tLoss: 1.806244\n",
      "Train Epoch: 2 [5760/14140 (41%)]\tLoss: 1.680077\n",
      "Train Epoch: 2 [6400/14140 (45%)]\tLoss: 2.011627\n",
      "Train Epoch: 2 [7040/14140 (50%)]\tLoss: 1.944512\n",
      "Train Epoch: 2 [7680/14140 (54%)]\tLoss: 1.587840\n",
      "Train Epoch: 2 [8320/14140 (59%)]\tLoss: 1.592879\n",
      "Train Epoch: 2 [8960/14140 (63%)]\tLoss: 2.075579\n",
      "Train Epoch: 2 [9600/14140 (68%)]\tLoss: 1.835099\n",
      "Train Epoch: 2 [10240/14140 (72%)]\tLoss: 1.771321\n",
      "Train Epoch: 2 [10880/14140 (77%)]\tLoss: 1.408208\n",
      "Train Epoch: 2 [11520/14140 (81%)]\tLoss: 1.502148\n",
      "Train Epoch: 2 [12160/14140 (86%)]\tLoss: 2.002163\n",
      "Train Epoch: 2 [12800/14140 (90%)]\tLoss: 1.706212\n",
      "Train Epoch: 2 [13440/14140 (95%)]\tLoss: 2.223002\n",
      "Train Epoch: 2 [13200/14140 (100%)]\tLoss: 1.621543\n",
      "Validation Accuracy: 0.4858\n",
      "Train Epoch: 3 [0/14140 (0%)]\tLoss: 1.547348\n",
      "Train Epoch: 3 [640/14140 (5%)]\tLoss: 1.791165\n",
      "Train Epoch: 3 [1280/14140 (9%)]\tLoss: 1.266484\n",
      "Train Epoch: 3 [1920/14140 (14%)]\tLoss: 1.561223\n",
      "Train Epoch: 3 [2560/14140 (18%)]\tLoss: 1.637659\n",
      "Train Epoch: 3 [3200/14140 (23%)]\tLoss: 1.952695\n",
      "Train Epoch: 3 [3840/14140 (27%)]\tLoss: 1.569536\n",
      "Train Epoch: 3 [4480/14140 (32%)]\tLoss: 1.391919\n",
      "Train Epoch: 3 [5120/14140 (36%)]\tLoss: 1.609561\n",
      "Train Epoch: 3 [5760/14140 (41%)]\tLoss: 1.651343\n",
      "Train Epoch: 3 [6400/14140 (45%)]\tLoss: 1.709625\n",
      "Train Epoch: 3 [7040/14140 (50%)]\tLoss: 1.058705\n",
      "Train Epoch: 3 [7680/14140 (54%)]\tLoss: 1.680146\n",
      "Train Epoch: 3 [8320/14140 (59%)]\tLoss: 1.579625\n",
      "Train Epoch: 3 [8960/14140 (63%)]\tLoss: 1.733890\n",
      "Train Epoch: 3 [9600/14140 (68%)]\tLoss: 1.474425\n",
      "Train Epoch: 3 [10240/14140 (72%)]\tLoss: 1.963504\n",
      "Train Epoch: 3 [10880/14140 (77%)]\tLoss: 1.450480\n",
      "Train Epoch: 3 [11520/14140 (81%)]\tLoss: 1.595282\n",
      "Train Epoch: 3 [12160/14140 (86%)]\tLoss: 1.446579\n",
      "Train Epoch: 3 [12800/14140 (90%)]\tLoss: 1.870992\n",
      "Train Epoch: 3 [13440/14140 (95%)]\tLoss: 1.480732\n",
      "Train Epoch: 3 [13200/14140 (100%)]\tLoss: 1.940795\n",
      "Validation Accuracy: 0.4792\n",
      "Train Epoch: 4 [0/14140 (0%)]\tLoss: 1.789013\n",
      "Train Epoch: 4 [640/14140 (5%)]\tLoss: 1.253272\n",
      "Train Epoch: 4 [1280/14140 (9%)]\tLoss: 1.192092\n",
      "Train Epoch: 4 [1920/14140 (14%)]\tLoss: 1.708359\n",
      "Train Epoch: 4 [2560/14140 (18%)]\tLoss: 1.251699\n",
      "Train Epoch: 4 [3200/14140 (23%)]\tLoss: 1.421285\n",
      "Train Epoch: 4 [3840/14140 (27%)]\tLoss: 1.876341\n",
      "Train Epoch: 4 [4480/14140 (32%)]\tLoss: 1.695218\n",
      "Train Epoch: 4 [5120/14140 (36%)]\tLoss: 1.834897\n",
      "Train Epoch: 4 [5760/14140 (41%)]\tLoss: 1.317286\n",
      "Train Epoch: 4 [6400/14140 (45%)]\tLoss: 1.482157\n",
      "Train Epoch: 4 [7040/14140 (50%)]\tLoss: 1.183708\n",
      "Train Epoch: 4 [7680/14140 (54%)]\tLoss: 1.554679\n",
      "Train Epoch: 4 [8320/14140 (59%)]\tLoss: 1.176244\n",
      "Train Epoch: 4 [8960/14140 (63%)]\tLoss: 1.625093\n",
      "Train Epoch: 4 [9600/14140 (68%)]\tLoss: 1.348550\n",
      "Train Epoch: 4 [10240/14140 (72%)]\tLoss: 1.456038\n",
      "Train Epoch: 4 [10880/14140 (77%)]\tLoss: 1.380228\n",
      "Train Epoch: 4 [11520/14140 (81%)]\tLoss: 1.489913\n",
      "Train Epoch: 4 [12160/14140 (86%)]\tLoss: 1.743026\n",
      "Train Epoch: 4 [12800/14140 (90%)]\tLoss: 1.738830\n",
      "Train Epoch: 4 [13440/14140 (95%)]\tLoss: 1.498417\n",
      "Train Epoch: 4 [13200/14140 (100%)]\tLoss: 1.504288\n",
      "Validation Accuracy: 0.4891\n",
      "Train Epoch: 5 [0/14140 (0%)]\tLoss: 1.084133\n",
      "Train Epoch: 5 [640/14140 (5%)]\tLoss: 1.421100\n",
      "Train Epoch: 5 [1280/14140 (9%)]\tLoss: 1.509039\n",
      "Train Epoch: 5 [1920/14140 (14%)]\tLoss: 1.040630\n",
      "Train Epoch: 5 [2560/14140 (18%)]\tLoss: 1.376877\n",
      "Train Epoch: 5 [3200/14140 (23%)]\tLoss: 1.442080\n",
      "Train Epoch: 5 [3840/14140 (27%)]\tLoss: 1.242434\n",
      "Train Epoch: 5 [4480/14140 (32%)]\tLoss: 1.190417\n",
      "Train Epoch: 5 [5120/14140 (36%)]\tLoss: 1.057275\n",
      "Train Epoch: 5 [5760/14140 (41%)]\tLoss: 1.454781\n",
      "Train Epoch: 5 [6400/14140 (45%)]\tLoss: 1.322167\n",
      "Train Epoch: 5 [7040/14140 (50%)]\tLoss: 1.393439\n",
      "Train Epoch: 5 [7680/14140 (54%)]\tLoss: 1.399968\n",
      "Train Epoch: 5 [8320/14140 (59%)]\tLoss: 1.562000\n",
      "Train Epoch: 5 [8960/14140 (63%)]\tLoss: 1.430630\n",
      "Train Epoch: 5 [9600/14140 (68%)]\tLoss: 1.769977\n",
      "Train Epoch: 5 [10240/14140 (72%)]\tLoss: 1.512186\n",
      "Train Epoch: 5 [10880/14140 (77%)]\tLoss: 1.193452\n",
      "Train Epoch: 5 [11520/14140 (81%)]\tLoss: 1.201071\n",
      "Train Epoch: 5 [12160/14140 (86%)]\tLoss: 1.500551\n",
      "Train Epoch: 5 [12800/14140 (90%)]\tLoss: 1.693092\n",
      "Train Epoch: 5 [13440/14140 (95%)]\tLoss: 1.569298\n",
      "Train Epoch: 5 [13200/14140 (100%)]\tLoss: 1.609695\n",
      "Validation Accuracy: 0.5020\n",
      "Train Epoch: 6 [0/14140 (0%)]\tLoss: 1.085693\n",
      "Train Epoch: 6 [640/14140 (5%)]\tLoss: 1.291253\n",
      "Train Epoch: 6 [1280/14140 (9%)]\tLoss: 1.322916\n",
      "Train Epoch: 6 [1920/14140 (14%)]\tLoss: 1.211891\n",
      "Train Epoch: 6 [2560/14140 (18%)]\tLoss: 1.147007\n",
      "Train Epoch: 6 [3200/14140 (23%)]\tLoss: 1.581433\n",
      "Train Epoch: 6 [3840/14140 (27%)]\tLoss: 1.417788\n",
      "Train Epoch: 6 [4480/14140 (32%)]\tLoss: 1.360542\n",
      "Train Epoch: 6 [5120/14140 (36%)]\tLoss: 1.320103\n",
      "Train Epoch: 6 [5760/14140 (41%)]\tLoss: 0.962743\n",
      "Train Epoch: 6 [6400/14140 (45%)]\tLoss: 1.298463\n",
      "Train Epoch: 6 [7040/14140 (50%)]\tLoss: 1.456450\n",
      "Train Epoch: 6 [7680/14140 (54%)]\tLoss: 1.747207\n",
      "Train Epoch: 6 [8320/14140 (59%)]\tLoss: 1.234128\n",
      "Train Epoch: 6 [8960/14140 (63%)]\tLoss: 1.385103\n",
      "Train Epoch: 6 [9600/14140 (68%)]\tLoss: 1.615838\n",
      "Train Epoch: 6 [10240/14140 (72%)]\tLoss: 1.020905\n",
      "Train Epoch: 6 [10880/14140 (77%)]\tLoss: 1.371042\n",
      "Train Epoch: 6 [11520/14140 (81%)]\tLoss: 1.128602\n",
      "Train Epoch: 6 [12160/14140 (86%)]\tLoss: 1.470090\n",
      "Train Epoch: 6 [12800/14140 (90%)]\tLoss: 1.441395\n",
      "Train Epoch: 6 [13440/14140 (95%)]\tLoss: 1.351849\n",
      "Train Epoch: 6 [13200/14140 (100%)]\tLoss: 1.079151\n",
      "Validation Accuracy: 0.4974\n",
      "Train Epoch: 7 [0/14140 (0%)]\tLoss: 1.245437\n",
      "Train Epoch: 7 [640/14140 (5%)]\tLoss: 1.242919\n",
      "Train Epoch: 7 [1280/14140 (9%)]\tLoss: 1.151040\n",
      "Train Epoch: 7 [1920/14140 (14%)]\tLoss: 1.403755\n",
      "Train Epoch: 7 [2560/14140 (18%)]\tLoss: 1.150601\n",
      "Train Epoch: 7 [3200/14140 (23%)]\tLoss: 1.615340\n",
      "Train Epoch: 7 [3840/14140 (27%)]\tLoss: 1.348364\n",
      "Train Epoch: 7 [4480/14140 (32%)]\tLoss: 1.277501\n",
      "Train Epoch: 7 [5120/14140 (36%)]\tLoss: 1.213230\n",
      "Train Epoch: 7 [5760/14140 (41%)]\tLoss: 1.163943\n",
      "Train Epoch: 7 [6400/14140 (45%)]\tLoss: 1.402403\n",
      "Train Epoch: 7 [7040/14140 (50%)]\tLoss: 0.797902\n",
      "Train Epoch: 7 [7680/14140 (54%)]\tLoss: 1.306488\n",
      "Train Epoch: 7 [8320/14140 (59%)]\tLoss: 1.108191\n",
      "Train Epoch: 7 [8960/14140 (63%)]\tLoss: 1.600306\n",
      "Train Epoch: 7 [9600/14140 (68%)]\tLoss: 0.899519\n",
      "Train Epoch: 7 [10240/14140 (72%)]\tLoss: 1.314791\n",
      "Train Epoch: 7 [10880/14140 (77%)]\tLoss: 1.331195\n",
      "Train Epoch: 7 [11520/14140 (81%)]\tLoss: 1.195397\n",
      "Train Epoch: 7 [12160/14140 (86%)]\tLoss: 1.429781\n",
      "Train Epoch: 7 [12800/14140 (90%)]\tLoss: 1.070720\n",
      "Train Epoch: 7 [13440/14140 (95%)]\tLoss: 1.315066\n",
      "Train Epoch: 7 [13200/14140 (100%)]\tLoss: 1.310905\n",
      "Validation Accuracy: 0.4987\n",
      "Train Epoch: 8 [0/14140 (0%)]\tLoss: 0.813775\n",
      "Train Epoch: 8 [640/14140 (5%)]\tLoss: 1.381608\n",
      "Train Epoch: 8 [1280/14140 (9%)]\tLoss: 1.010816\n",
      "Train Epoch: 8 [1920/14140 (14%)]\tLoss: 1.341610\n",
      "Train Epoch: 8 [2560/14140 (18%)]\tLoss: 1.007741\n",
      "Train Epoch: 8 [3200/14140 (23%)]\tLoss: 1.356684\n",
      "Train Epoch: 8 [3840/14140 (27%)]\tLoss: 1.109050\n",
      "Train Epoch: 8 [4480/14140 (32%)]\tLoss: 1.167196\n",
      "Train Epoch: 8 [5120/14140 (36%)]\tLoss: 1.469883\n",
      "Train Epoch: 8 [5760/14140 (41%)]\tLoss: 0.890629\n",
      "Train Epoch: 8 [6400/14140 (45%)]\tLoss: 1.263798\n",
      "Train Epoch: 8 [7040/14140 (50%)]\tLoss: 1.426080\n",
      "Train Epoch: 8 [7680/14140 (54%)]\tLoss: 0.995938\n",
      "Train Epoch: 8 [8320/14140 (59%)]\tLoss: 0.883865\n",
      "Train Epoch: 8 [8960/14140 (63%)]\tLoss: 1.599252\n",
      "Train Epoch: 8 [9600/14140 (68%)]\tLoss: 1.759847\n",
      "Train Epoch: 8 [10240/14140 (72%)]\tLoss: 1.265632\n",
      "Train Epoch: 8 [10880/14140 (77%)]\tLoss: 1.298388\n",
      "Train Epoch: 8 [11520/14140 (81%)]\tLoss: 1.284408\n",
      "Train Epoch: 8 [12160/14140 (86%)]\tLoss: 1.434358\n",
      "Train Epoch: 8 [12800/14140 (90%)]\tLoss: 1.641788\n",
      "Train Epoch: 8 [13440/14140 (95%)]\tLoss: 1.367035\n",
      "Train Epoch: 8 [13200/14140 (100%)]\tLoss: 1.082720\n",
      "Validation Accuracy: 0.4987\n",
      "Train Epoch: 9 [0/14140 (0%)]\tLoss: 0.718637\n",
      "Train Epoch: 9 [640/14140 (5%)]\tLoss: 0.706543\n",
      "Train Epoch: 9 [1280/14140 (9%)]\tLoss: 0.940941\n",
      "Train Epoch: 9 [1920/14140 (14%)]\tLoss: 0.725914\n",
      "Train Epoch: 9 [2560/14140 (18%)]\tLoss: 1.294432\n",
      "Train Epoch: 9 [3200/14140 (23%)]\tLoss: 0.887028\n",
      "Train Epoch: 9 [3840/14140 (27%)]\tLoss: 1.491088\n",
      "Train Epoch: 9 [4480/14140 (32%)]\tLoss: 1.189849\n",
      "Train Epoch: 9 [5120/14140 (36%)]\tLoss: 1.255485\n",
      "Train Epoch: 9 [5760/14140 (41%)]\tLoss: 1.224919\n",
      "Train Epoch: 9 [6400/14140 (45%)]\tLoss: 1.161126\n",
      "Train Epoch: 9 [7040/14140 (50%)]\tLoss: 1.345414\n",
      "Train Epoch: 9 [7680/14140 (54%)]\tLoss: 0.943504\n",
      "Train Epoch: 9 [8320/14140 (59%)]\tLoss: 1.415274\n",
      "Train Epoch: 9 [8960/14140 (63%)]\tLoss: 0.944880\n",
      "Train Epoch: 9 [9600/14140 (68%)]\tLoss: 0.801759\n",
      "Train Epoch: 9 [10240/14140 (72%)]\tLoss: 1.679639\n",
      "Train Epoch: 9 [10880/14140 (77%)]\tLoss: 1.387984\n",
      "Train Epoch: 9 [11520/14140 (81%)]\tLoss: 0.967005\n",
      "Train Epoch: 9 [12160/14140 (86%)]\tLoss: 1.459074\n",
      "Train Epoch: 9 [12800/14140 (90%)]\tLoss: 1.604316\n",
      "Train Epoch: 9 [13440/14140 (95%)]\tLoss: 1.342052\n",
      "Train Epoch: 9 [13200/14140 (100%)]\tLoss: 1.320023\n",
      "Validation Accuracy: 0.5026\n",
      "Train Epoch: 10 [0/14140 (0%)]\tLoss: 1.237133\n",
      "Train Epoch: 10 [640/14140 (5%)]\tLoss: 1.070755\n",
      "Train Epoch: 10 [1280/14140 (9%)]\tLoss: 1.552080\n",
      "Train Epoch: 10 [1920/14140 (14%)]\tLoss: 0.744609\n",
      "Train Epoch: 10 [2560/14140 (18%)]\tLoss: 1.029318\n",
      "Train Epoch: 10 [3200/14140 (23%)]\tLoss: 1.291751\n",
      "Train Epoch: 10 [3840/14140 (27%)]\tLoss: 0.978359\n",
      "Train Epoch: 10 [4480/14140 (32%)]\tLoss: 0.976753\n",
      "Train Epoch: 10 [5120/14140 (36%)]\tLoss: 1.169330\n",
      "Train Epoch: 10 [5760/14140 (41%)]\tLoss: 1.192540\n",
      "Train Epoch: 10 [6400/14140 (45%)]\tLoss: 1.075750\n",
      "Train Epoch: 10 [7040/14140 (50%)]\tLoss: 0.838566\n",
      "Train Epoch: 10 [7680/14140 (54%)]\tLoss: 1.200521\n",
      "Train Epoch: 10 [8320/14140 (59%)]\tLoss: 0.981491\n",
      "Train Epoch: 10 [8960/14140 (63%)]\tLoss: 1.048783\n",
      "Train Epoch: 10 [9600/14140 (68%)]\tLoss: 1.644492\n",
      "Train Epoch: 10 [10240/14140 (72%)]\tLoss: 1.146698\n",
      "Train Epoch: 10 [10880/14140 (77%)]\tLoss: 1.121488\n",
      "Train Epoch: 10 [11520/14140 (81%)]\tLoss: 1.113865\n",
      "Train Epoch: 10 [12160/14140 (86%)]\tLoss: 1.224098\n",
      "Train Epoch: 10 [12800/14140 (90%)]\tLoss: 1.788798\n",
      "Train Epoch: 10 [13440/14140 (95%)]\tLoss: 1.327246\n",
      "Train Epoch: 10 [13200/14140 (100%)]\tLoss: 1.076587\n",
      "Validation Accuracy: 0.5030\n",
      "Train Epoch: 11 [0/14140 (0%)]\tLoss: 1.107201\n",
      "Train Epoch: 11 [640/14140 (5%)]\tLoss: 1.023360\n",
      "Train Epoch: 11 [1280/14140 (9%)]\tLoss: 1.134132\n",
      "Train Epoch: 11 [1920/14140 (14%)]\tLoss: 1.067163\n",
      "Train Epoch: 11 [2560/14140 (18%)]\tLoss: 0.942275\n",
      "Train Epoch: 11 [3200/14140 (23%)]\tLoss: 1.028852\n",
      "Train Epoch: 11 [3840/14140 (27%)]\tLoss: 1.081135\n",
      "Train Epoch: 11 [4480/14140 (32%)]\tLoss: 1.016035\n",
      "Train Epoch: 11 [5120/14140 (36%)]\tLoss: 1.000820\n",
      "Train Epoch: 11 [5760/14140 (41%)]\tLoss: 1.156196\n",
      "Train Epoch: 11 [6400/14140 (45%)]\tLoss: 1.055915\n",
      "Train Epoch: 11 [7040/14140 (50%)]\tLoss: 1.115984\n",
      "Train Epoch: 11 [7680/14140 (54%)]\tLoss: 1.162498\n",
      "Train Epoch: 11 [8320/14140 (59%)]\tLoss: 1.257820\n",
      "Train Epoch: 11 [8960/14140 (63%)]\tLoss: 1.379280\n",
      "Train Epoch: 11 [9600/14140 (68%)]\tLoss: 1.088616\n",
      "Train Epoch: 11 [10240/14140 (72%)]\tLoss: 1.017599\n",
      "Train Epoch: 11 [10880/14140 (77%)]\tLoss: 1.163202\n",
      "Train Epoch: 11 [11520/14140 (81%)]\tLoss: 1.010699\n",
      "Train Epoch: 11 [12160/14140 (86%)]\tLoss: 1.316652\n",
      "Train Epoch: 11 [12800/14140 (90%)]\tLoss: 1.120867\n",
      "Train Epoch: 11 [13440/14140 (95%)]\tLoss: 1.188942\n",
      "Train Epoch: 11 [13200/14140 (100%)]\tLoss: 1.594192\n",
      "Validation Accuracy: 0.4993\n",
      "Train Epoch: 12 [0/14140 (0%)]\tLoss: 0.707834\n",
      "Train Epoch: 12 [640/14140 (5%)]\tLoss: 0.708011\n",
      "Train Epoch: 12 [1280/14140 (9%)]\tLoss: 0.820906\n",
      "Train Epoch: 12 [1920/14140 (14%)]\tLoss: 1.236865\n",
      "Train Epoch: 12 [2560/14140 (18%)]\tLoss: 1.260075\n",
      "Train Epoch: 12 [3200/14140 (23%)]\tLoss: 0.970939\n",
      "Train Epoch: 12 [3840/14140 (27%)]\tLoss: 0.975268\n",
      "Train Epoch: 12 [4480/14140 (32%)]\tLoss: 1.126300\n",
      "Train Epoch: 12 [5120/14140 (36%)]\tLoss: 1.102114\n",
      "Train Epoch: 12 [5760/14140 (41%)]\tLoss: 0.929104\n",
      "Train Epoch: 12 [6400/14140 (45%)]\tLoss: 1.145919\n",
      "Train Epoch: 12 [7040/14140 (50%)]\tLoss: 1.010749\n",
      "Train Epoch: 12 [7680/14140 (54%)]\tLoss: 0.980092\n",
      "Train Epoch: 12 [8320/14140 (59%)]\tLoss: 1.191716\n",
      "Train Epoch: 12 [8960/14140 (63%)]\tLoss: 1.335088\n",
      "Train Epoch: 12 [9600/14140 (68%)]\tLoss: 1.013130\n",
      "Train Epoch: 12 [10240/14140 (72%)]\tLoss: 0.753319\n",
      "Train Epoch: 12 [10880/14140 (77%)]\tLoss: 0.924115\n",
      "Train Epoch: 12 [11520/14140 (81%)]\tLoss: 0.713159\n",
      "Train Epoch: 12 [12160/14140 (86%)]\tLoss: 1.351181\n",
      "Train Epoch: 12 [12800/14140 (90%)]\tLoss: 1.198872\n",
      "Train Epoch: 12 [13440/14140 (95%)]\tLoss: 1.089480\n",
      "Train Epoch: 12 [13200/14140 (100%)]\tLoss: 0.933572\n",
      "Validation Accuracy: 0.5083\n",
      "Train Epoch: 13 [0/14140 (0%)]\tLoss: 1.366640\n",
      "Train Epoch: 13 [640/14140 (5%)]\tLoss: 0.745713\n",
      "Train Epoch: 13 [1280/14140 (9%)]\tLoss: 1.159777\n",
      "Train Epoch: 13 [1920/14140 (14%)]\tLoss: 1.140378\n",
      "Train Epoch: 13 [2560/14140 (18%)]\tLoss: 1.001932\n",
      "Train Epoch: 13 [3200/14140 (23%)]\tLoss: 0.887905\n",
      "Train Epoch: 13 [3840/14140 (27%)]\tLoss: 1.190238\n",
      "Train Epoch: 13 [4480/14140 (32%)]\tLoss: 0.809471\n",
      "Train Epoch: 13 [5120/14140 (36%)]\tLoss: 1.024941\n",
      "Train Epoch: 13 [5760/14140 (41%)]\tLoss: 0.914104\n",
      "Train Epoch: 13 [6400/14140 (45%)]\tLoss: 0.787192\n",
      "Train Epoch: 13 [7040/14140 (50%)]\tLoss: 0.991421\n",
      "Train Epoch: 13 [7680/14140 (54%)]\tLoss: 0.819773\n",
      "Train Epoch: 13 [8320/14140 (59%)]\tLoss: 1.134094\n",
      "Train Epoch: 13 [8960/14140 (63%)]\tLoss: 1.170951\n",
      "Train Epoch: 13 [9600/14140 (68%)]\tLoss: 0.837639\n",
      "Train Epoch: 13 [10240/14140 (72%)]\tLoss: 1.099103\n",
      "Train Epoch: 13 [10880/14140 (77%)]\tLoss: 1.017235\n",
      "Train Epoch: 13 [11520/14140 (81%)]\tLoss: 0.908824\n",
      "Train Epoch: 13 [12160/14140 (86%)]\tLoss: 1.325494\n",
      "Train Epoch: 13 [12800/14140 (90%)]\tLoss: 1.255422\n",
      "Train Epoch: 13 [13440/14140 (95%)]\tLoss: 0.854814\n",
      "Train Epoch: 13 [13200/14140 (100%)]\tLoss: 0.908815\n",
      "Validation Accuracy: 0.4964\n",
      "Train Epoch: 14 [0/14140 (0%)]\tLoss: 1.085413\n",
      "Train Epoch: 14 [640/14140 (5%)]\tLoss: 0.657625\n",
      "Train Epoch: 14 [1280/14140 (9%)]\tLoss: 1.231509\n",
      "Train Epoch: 14 [1920/14140 (14%)]\tLoss: 0.753181\n",
      "Train Epoch: 14 [2560/14140 (18%)]\tLoss: 0.939350\n",
      "Train Epoch: 14 [3200/14140 (23%)]\tLoss: 1.051414\n",
      "Train Epoch: 14 [3840/14140 (27%)]\tLoss: 0.821690\n",
      "Train Epoch: 14 [4480/14140 (32%)]\tLoss: 0.951154\n",
      "Train Epoch: 14 [5120/14140 (36%)]\tLoss: 0.978386\n",
      "Train Epoch: 14 [5760/14140 (41%)]\tLoss: 0.856037\n",
      "Train Epoch: 14 [6400/14140 (45%)]\tLoss: 1.117336\n",
      "Train Epoch: 14 [7040/14140 (50%)]\tLoss: 1.057098\n",
      "Train Epoch: 14 [7680/14140 (54%)]\tLoss: 0.750958\n",
      "Train Epoch: 14 [8320/14140 (59%)]\tLoss: 0.991870\n",
      "Train Epoch: 14 [8960/14140 (63%)]\tLoss: 1.184801\n",
      "Train Epoch: 14 [9600/14140 (68%)]\tLoss: 1.165882\n",
      "Train Epoch: 14 [10240/14140 (72%)]\tLoss: 1.370407\n",
      "Train Epoch: 14 [10880/14140 (77%)]\tLoss: 0.790640\n",
      "Train Epoch: 14 [11520/14140 (81%)]\tLoss: 0.998927\n",
      "Train Epoch: 14 [12160/14140 (86%)]\tLoss: 1.185919\n",
      "Train Epoch: 14 [12800/14140 (90%)]\tLoss: 0.844927\n",
      "Train Epoch: 14 [13440/14140 (95%)]\tLoss: 0.674893\n",
      "Train Epoch: 14 [13200/14140 (100%)]\tLoss: 0.956356\n",
      "Validation Accuracy: 0.4977\n",
      "Train Epoch: 15 [0/14140 (0%)]\tLoss: 1.056312\n",
      "Train Epoch: 15 [640/14140 (5%)]\tLoss: 0.858403\n",
      "Train Epoch: 15 [1280/14140 (9%)]\tLoss: 0.944656\n",
      "Train Epoch: 15 [1920/14140 (14%)]\tLoss: 0.818651\n",
      "Train Epoch: 15 [2560/14140 (18%)]\tLoss: 1.094500\n",
      "Train Epoch: 15 [3200/14140 (23%)]\tLoss: 0.942913\n",
      "Train Epoch: 15 [3840/14140 (27%)]\tLoss: 1.019761\n",
      "Train Epoch: 15 [4480/14140 (32%)]\tLoss: 0.982867\n",
      "Train Epoch: 15 [5120/14140 (36%)]\tLoss: 0.709035\n",
      "Train Epoch: 15 [5760/14140 (41%)]\tLoss: 1.029755\n",
      "Train Epoch: 15 [6400/14140 (45%)]\tLoss: 0.862213\n",
      "Train Epoch: 15 [7040/14140 (50%)]\tLoss: 1.132933\n",
      "Train Epoch: 15 [7680/14140 (54%)]\tLoss: 0.652128\n",
      "Train Epoch: 15 [8320/14140 (59%)]\tLoss: 0.871012\n",
      "Train Epoch: 15 [8960/14140 (63%)]\tLoss: 1.229631\n",
      "Train Epoch: 15 [9600/14140 (68%)]\tLoss: 1.025525\n",
      "Train Epoch: 15 [10240/14140 (72%)]\tLoss: 1.089901\n",
      "Train Epoch: 15 [10880/14140 (77%)]\tLoss: 0.752334\n",
      "Train Epoch: 15 [11520/14140 (81%)]\tLoss: 1.214564\n",
      "Train Epoch: 15 [12160/14140 (86%)]\tLoss: 0.972573\n",
      "Train Epoch: 15 [12800/14140 (90%)]\tLoss: 1.034448\n",
      "Train Epoch: 15 [13440/14140 (95%)]\tLoss: 0.784547\n",
      "Train Epoch: 15 [13200/14140 (100%)]\tLoss: 1.116915\n",
      "Validation Accuracy: 0.4914\n",
      "Train Epoch: 16 [0/14140 (0%)]\tLoss: 0.799072\n",
      "Train Epoch: 16 [640/14140 (5%)]\tLoss: 0.741096\n",
      "Train Epoch: 16 [1280/14140 (9%)]\tLoss: 0.801421\n",
      "Train Epoch: 16 [1920/14140 (14%)]\tLoss: 0.740477\n",
      "Train Epoch: 16 [2560/14140 (18%)]\tLoss: 0.762127\n",
      "Train Epoch: 16 [3200/14140 (23%)]\tLoss: 0.730039\n",
      "Train Epoch: 16 [3840/14140 (27%)]\tLoss: 0.645986\n",
      "Train Epoch: 16 [4480/14140 (32%)]\tLoss: 0.671405\n",
      "Train Epoch: 16 [5120/14140 (36%)]\tLoss: 0.672120\n",
      "Train Epoch: 16 [5760/14140 (41%)]\tLoss: 0.918433\n",
      "Train Epoch: 16 [6400/14140 (45%)]\tLoss: 0.654923\n",
      "Train Epoch: 16 [7040/14140 (50%)]\tLoss: 0.681129\n",
      "Train Epoch: 16 [7680/14140 (54%)]\tLoss: 1.029105\n",
      "Train Epoch: 16 [8320/14140 (59%)]\tLoss: 1.139872\n",
      "Train Epoch: 16 [8960/14140 (63%)]\tLoss: 0.954283\n",
      "Train Epoch: 16 [9600/14140 (68%)]\tLoss: 0.899817\n",
      "Train Epoch: 16 [10240/14140 (72%)]\tLoss: 0.848485\n",
      "Train Epoch: 16 [10880/14140 (77%)]\tLoss: 0.920128\n",
      "Train Epoch: 16 [11520/14140 (81%)]\tLoss: 0.760639\n",
      "Train Epoch: 16 [12160/14140 (86%)]\tLoss: 0.729343\n",
      "Train Epoch: 16 [12800/14140 (90%)]\tLoss: 0.844416\n",
      "Train Epoch: 16 [13440/14140 (95%)]\tLoss: 0.732436\n",
      "Train Epoch: 16 [13200/14140 (100%)]\tLoss: 1.130747\n",
      "Validation Accuracy: 0.4954\n",
      "Train Epoch: 17 [0/14140 (0%)]\tLoss: 0.768655\n",
      "Train Epoch: 17 [640/14140 (5%)]\tLoss: 0.688675\n",
      "Train Epoch: 17 [1280/14140 (9%)]\tLoss: 0.830971\n",
      "Train Epoch: 17 [1920/14140 (14%)]\tLoss: 0.765913\n",
      "Train Epoch: 17 [2560/14140 (18%)]\tLoss: 0.576617\n",
      "Train Epoch: 17 [3200/14140 (23%)]\tLoss: 1.035266\n",
      "Train Epoch: 17 [3840/14140 (27%)]\tLoss: 0.986124\n",
      "Train Epoch: 17 [4480/14140 (32%)]\tLoss: 1.085284\n",
      "Train Epoch: 17 [5120/14140 (36%)]\tLoss: 0.792996\n",
      "Train Epoch: 17 [5760/14140 (41%)]\tLoss: 0.908106\n",
      "Train Epoch: 17 [6400/14140 (45%)]\tLoss: 0.720672\n",
      "Train Epoch: 17 [7040/14140 (50%)]\tLoss: 0.690574\n",
      "Train Epoch: 17 [7680/14140 (54%)]\tLoss: 0.848260\n",
      "Train Epoch: 17 [8320/14140 (59%)]\tLoss: 1.089658\n",
      "Train Epoch: 17 [8960/14140 (63%)]\tLoss: 0.950865\n",
      "Train Epoch: 17 [9600/14140 (68%)]\tLoss: 0.809108\n",
      "Train Epoch: 17 [10240/14140 (72%)]\tLoss: 0.870457\n",
      "Train Epoch: 17 [10880/14140 (77%)]\tLoss: 0.725096\n",
      "Train Epoch: 17 [11520/14140 (81%)]\tLoss: 0.830051\n",
      "Train Epoch: 17 [12160/14140 (86%)]\tLoss: 0.856583\n",
      "Train Epoch: 17 [12800/14140 (90%)]\tLoss: 0.670426\n",
      "Train Epoch: 17 [13440/14140 (95%)]\tLoss: 0.675796\n",
      "Train Epoch: 17 [13200/14140 (100%)]\tLoss: 0.610098\n",
      "Validation Accuracy: 0.5083\n",
      "Train Epoch: 18 [0/14140 (0%)]\tLoss: 0.798533\n",
      "Train Epoch: 18 [640/14140 (5%)]\tLoss: 0.602850\n",
      "Train Epoch: 18 [1280/14140 (9%)]\tLoss: 0.765757\n",
      "Train Epoch: 18 [1920/14140 (14%)]\tLoss: 0.854072\n",
      "Train Epoch: 18 [2560/14140 (18%)]\tLoss: 0.817883\n",
      "Train Epoch: 18 [3200/14140 (23%)]\tLoss: 0.607896\n",
      "Train Epoch: 18 [3840/14140 (27%)]\tLoss: 0.531635\n",
      "Train Epoch: 18 [4480/14140 (32%)]\tLoss: 0.617199\n",
      "Train Epoch: 18 [5120/14140 (36%)]\tLoss: 0.679847\n",
      "Train Epoch: 18 [5760/14140 (41%)]\tLoss: 1.136542\n",
      "Train Epoch: 18 [6400/14140 (45%)]\tLoss: 0.498435\n",
      "Train Epoch: 18 [7040/14140 (50%)]\tLoss: 0.794655\n",
      "Train Epoch: 18 [7680/14140 (54%)]\tLoss: 0.962163\n",
      "Train Epoch: 18 [8320/14140 (59%)]\tLoss: 1.121518\n",
      "Train Epoch: 18 [8960/14140 (63%)]\tLoss: 0.892523\n",
      "Train Epoch: 18 [9600/14140 (68%)]\tLoss: 1.023258\n",
      "Train Epoch: 18 [10240/14140 (72%)]\tLoss: 0.543368\n",
      "Train Epoch: 18 [10880/14140 (77%)]\tLoss: 1.196525\n",
      "Train Epoch: 18 [11520/14140 (81%)]\tLoss: 0.904500\n",
      "Train Epoch: 18 [12160/14140 (86%)]\tLoss: 0.919551\n",
      "Train Epoch: 18 [12800/14140 (90%)]\tLoss: 0.934066\n",
      "Train Epoch: 18 [13440/14140 (95%)]\tLoss: 0.708961\n",
      "Train Epoch: 18 [13200/14140 (100%)]\tLoss: 0.895628\n",
      "Validation Accuracy: 0.5079\n",
      "Train Epoch: 19 [0/14140 (0%)]\tLoss: 0.736765\n",
      "Train Epoch: 19 [640/14140 (5%)]\tLoss: 0.840551\n",
      "Train Epoch: 19 [1280/14140 (9%)]\tLoss: 0.574151\n",
      "Train Epoch: 19 [1920/14140 (14%)]\tLoss: 0.709503\n",
      "Train Epoch: 19 [2560/14140 (18%)]\tLoss: 0.740839\n",
      "Train Epoch: 19 [3200/14140 (23%)]\tLoss: 0.816034\n",
      "Train Epoch: 19 [3840/14140 (27%)]\tLoss: 0.734014\n",
      "Train Epoch: 19 [4480/14140 (32%)]\tLoss: 0.679608\n",
      "Train Epoch: 19 [5120/14140 (36%)]\tLoss: 0.743261\n",
      "Train Epoch: 19 [5760/14140 (41%)]\tLoss: 0.727379\n",
      "Train Epoch: 19 [6400/14140 (45%)]\tLoss: 0.712009\n",
      "Train Epoch: 19 [7040/14140 (50%)]\tLoss: 1.050711\n",
      "Train Epoch: 19 [7680/14140 (54%)]\tLoss: 0.800476\n",
      "Train Epoch: 19 [8320/14140 (59%)]\tLoss: 0.653380\n",
      "Train Epoch: 19 [8960/14140 (63%)]\tLoss: 0.819528\n",
      "Train Epoch: 19 [9600/14140 (68%)]\tLoss: 0.732570\n",
      "Train Epoch: 19 [10240/14140 (72%)]\tLoss: 1.001748\n",
      "Train Epoch: 19 [10880/14140 (77%)]\tLoss: 0.668519\n",
      "Train Epoch: 19 [11520/14140 (81%)]\tLoss: 0.781799\n",
      "Train Epoch: 19 [12160/14140 (86%)]\tLoss: 0.753419\n",
      "Train Epoch: 19 [12800/14140 (90%)]\tLoss: 0.717214\n",
      "Train Epoch: 19 [13440/14140 (95%)]\tLoss: 0.810122\n",
      "Train Epoch: 19 [13200/14140 (100%)]\tLoss: 0.780138\n",
      "Validation Accuracy: 0.4954\n",
      "Train Epoch: 20 [0/14140 (0%)]\tLoss: 0.754808\n",
      "Train Epoch: 20 [640/14140 (5%)]\tLoss: 0.767469\n",
      "Train Epoch: 20 [1280/14140 (9%)]\tLoss: 0.727601\n",
      "Train Epoch: 20 [1920/14140 (14%)]\tLoss: 0.728635\n",
      "Train Epoch: 20 [2560/14140 (18%)]\tLoss: 0.739230\n",
      "Train Epoch: 20 [3200/14140 (23%)]\tLoss: 0.677754\n",
      "Train Epoch: 20 [3840/14140 (27%)]\tLoss: 0.926219\n",
      "Train Epoch: 20 [4480/14140 (32%)]\tLoss: 0.828409\n",
      "Train Epoch: 20 [5120/14140 (36%)]\tLoss: 0.613883\n",
      "Train Epoch: 20 [5760/14140 (41%)]\tLoss: 0.873223\n",
      "Train Epoch: 20 [6400/14140 (45%)]\tLoss: 0.752257\n",
      "Train Epoch: 20 [7040/14140 (50%)]\tLoss: 1.054358\n",
      "Train Epoch: 20 [7680/14140 (54%)]\tLoss: 0.570101\n",
      "Train Epoch: 20 [8320/14140 (59%)]\tLoss: 0.635875\n",
      "Train Epoch: 20 [8960/14140 (63%)]\tLoss: 0.760970\n",
      "Train Epoch: 20 [9600/14140 (68%)]\tLoss: 0.948418\n",
      "Train Epoch: 20 [10240/14140 (72%)]\tLoss: 0.746013\n",
      "Train Epoch: 20 [10880/14140 (77%)]\tLoss: 0.763144\n",
      "Train Epoch: 20 [11520/14140 (81%)]\tLoss: 0.783148\n",
      "Train Epoch: 20 [12160/14140 (86%)]\tLoss: 0.950307\n",
      "Train Epoch: 20 [12800/14140 (90%)]\tLoss: 0.853555\n",
      "Train Epoch: 20 [13440/14140 (95%)]\tLoss: 0.706492\n",
      "Train Epoch: 20 [13200/14140 (100%)]\tLoss: 0.910391\n",
      "Validation Accuracy: 0.5053\n",
      "Train Epoch: 21 [0/14140 (0%)]\tLoss: 0.737566\n",
      "Train Epoch: 21 [640/14140 (5%)]\tLoss: 0.817163\n",
      "Train Epoch: 21 [1280/14140 (9%)]\tLoss: 0.487821\n",
      "Train Epoch: 21 [1920/14140 (14%)]\tLoss: 0.698828\n",
      "Train Epoch: 21 [2560/14140 (18%)]\tLoss: 0.412789\n",
      "Train Epoch: 21 [3200/14140 (23%)]\tLoss: 0.673714\n",
      "Train Epoch: 21 [3840/14140 (27%)]\tLoss: 0.800574\n",
      "Train Epoch: 21 [4480/14140 (32%)]\tLoss: 0.749442\n",
      "Train Epoch: 21 [5120/14140 (36%)]\tLoss: 0.712124\n",
      "Train Epoch: 21 [5760/14140 (41%)]\tLoss: 0.635937\n",
      "Train Epoch: 21 [6400/14140 (45%)]\tLoss: 0.620301\n",
      "Train Epoch: 21 [7040/14140 (50%)]\tLoss: 0.634010\n",
      "Train Epoch: 21 [7680/14140 (54%)]\tLoss: 0.830028\n",
      "Train Epoch: 21 [8320/14140 (59%)]\tLoss: 0.929255\n",
      "Train Epoch: 21 [8960/14140 (63%)]\tLoss: 0.753430\n",
      "Train Epoch: 21 [9600/14140 (68%)]\tLoss: 0.676887\n",
      "Train Epoch: 21 [10240/14140 (72%)]\tLoss: 0.613893\n",
      "Train Epoch: 21 [10880/14140 (77%)]\tLoss: 0.630768\n",
      "Train Epoch: 21 [11520/14140 (81%)]\tLoss: 0.450815\n",
      "Train Epoch: 21 [12160/14140 (86%)]\tLoss: 1.067380\n",
      "Train Epoch: 21 [12800/14140 (90%)]\tLoss: 0.974720\n",
      "Train Epoch: 21 [13440/14140 (95%)]\tLoss: 0.902816\n",
      "Train Epoch: 21 [13200/14140 (100%)]\tLoss: 0.827769\n",
      "Validation Accuracy: 0.4983\n",
      "Train Epoch: 22 [0/14140 (0%)]\tLoss: 0.600747\n",
      "Train Epoch: 22 [640/14140 (5%)]\tLoss: 0.756606\n",
      "Train Epoch: 22 [1280/14140 (9%)]\tLoss: 0.672558\n",
      "Train Epoch: 22 [1920/14140 (14%)]\tLoss: 0.479409\n",
      "Train Epoch: 22 [2560/14140 (18%)]\tLoss: 0.713765\n",
      "Train Epoch: 22 [3200/14140 (23%)]\tLoss: 0.646086\n",
      "Train Epoch: 22 [3840/14140 (27%)]\tLoss: 0.559700\n",
      "Train Epoch: 22 [4480/14140 (32%)]\tLoss: 0.705727\n",
      "Train Epoch: 22 [5120/14140 (36%)]\tLoss: 0.853316\n",
      "Train Epoch: 22 [5760/14140 (41%)]\tLoss: 0.774473\n",
      "Train Epoch: 22 [6400/14140 (45%)]\tLoss: 0.784502\n",
      "Train Epoch: 22 [7040/14140 (50%)]\tLoss: 1.019936\n",
      "Train Epoch: 22 [7680/14140 (54%)]\tLoss: 0.630253\n",
      "Train Epoch: 22 [8320/14140 (59%)]\tLoss: 0.761334\n",
      "Train Epoch: 22 [8960/14140 (63%)]\tLoss: 0.633602\n",
      "Train Epoch: 22 [9600/14140 (68%)]\tLoss: 0.935940\n",
      "Train Epoch: 22 [10240/14140 (72%)]\tLoss: 0.668548\n",
      "Train Epoch: 22 [10880/14140 (77%)]\tLoss: 0.889448\n",
      "Train Epoch: 22 [11520/14140 (81%)]\tLoss: 0.849434\n",
      "Train Epoch: 22 [12160/14140 (86%)]\tLoss: 0.579997\n",
      "Train Epoch: 22 [12800/14140 (90%)]\tLoss: 0.821530\n",
      "Train Epoch: 22 [13440/14140 (95%)]\tLoss: 0.810188\n",
      "Train Epoch: 22 [13200/14140 (100%)]\tLoss: 1.049488\n",
      "Validation Accuracy: 0.4967\n",
      "Train Epoch: 23 [0/14140 (0%)]\tLoss: 0.751345\n",
      "Train Epoch: 23 [640/14140 (5%)]\tLoss: 0.618137\n",
      "Train Epoch: 23 [1280/14140 (9%)]\tLoss: 0.686091\n",
      "Train Epoch: 23 [1920/14140 (14%)]\tLoss: 0.636692\n",
      "Train Epoch: 23 [2560/14140 (18%)]\tLoss: 0.545373\n",
      "Train Epoch: 23 [3200/14140 (23%)]\tLoss: 0.548632\n",
      "Train Epoch: 23 [3840/14140 (27%)]\tLoss: 0.757507\n",
      "Train Epoch: 23 [4480/14140 (32%)]\tLoss: 0.814053\n",
      "Train Epoch: 23 [5120/14140 (36%)]\tLoss: 0.666056\n",
      "Train Epoch: 23 [5760/14140 (41%)]\tLoss: 0.827322\n",
      "Train Epoch: 23 [6400/14140 (45%)]\tLoss: 0.660123\n",
      "Train Epoch: 23 [7040/14140 (50%)]\tLoss: 0.699109\n",
      "Train Epoch: 23 [7680/14140 (54%)]\tLoss: 0.842881\n",
      "Train Epoch: 23 [8320/14140 (59%)]\tLoss: 0.795782\n",
      "Train Epoch: 23 [8960/14140 (63%)]\tLoss: 0.606843\n",
      "Train Epoch: 23 [9600/14140 (68%)]\tLoss: 0.571270\n",
      "Train Epoch: 23 [10240/14140 (72%)]\tLoss: 0.577175\n",
      "Train Epoch: 23 [10880/14140 (77%)]\tLoss: 1.007238\n",
      "Train Epoch: 23 [11520/14140 (81%)]\tLoss: 0.654431\n",
      "Train Epoch: 23 [12160/14140 (86%)]\tLoss: 0.513196\n",
      "Train Epoch: 23 [12800/14140 (90%)]\tLoss: 0.950306\n",
      "Train Epoch: 23 [13440/14140 (95%)]\tLoss: 0.880255\n",
      "Train Epoch: 23 [13200/14140 (100%)]\tLoss: 1.065272\n",
      "Validation Accuracy: 0.4944\n",
      "Train Epoch: 24 [0/14140 (0%)]\tLoss: 0.640043\n",
      "Train Epoch: 24 [640/14140 (5%)]\tLoss: 0.650410\n",
      "Train Epoch: 24 [1280/14140 (9%)]\tLoss: 0.613600\n",
      "Train Epoch: 24 [1920/14140 (14%)]\tLoss: 0.496739\n",
      "Train Epoch: 24 [2560/14140 (18%)]\tLoss: 0.921288\n",
      "Train Epoch: 24 [3200/14140 (23%)]\tLoss: 0.615735\n",
      "Train Epoch: 24 [3840/14140 (27%)]\tLoss: 0.501488\n",
      "Train Epoch: 24 [4480/14140 (32%)]\tLoss: 0.868332\n",
      "Train Epoch: 24 [5120/14140 (36%)]\tLoss: 0.924226\n",
      "Train Epoch: 24 [5760/14140 (41%)]\tLoss: 0.531801\n",
      "Train Epoch: 24 [6400/14140 (45%)]\tLoss: 0.767092\n",
      "Train Epoch: 24 [7040/14140 (50%)]\tLoss: 0.685880\n",
      "Train Epoch: 24 [7680/14140 (54%)]\tLoss: 0.760358\n",
      "Train Epoch: 24 [8320/14140 (59%)]\tLoss: 0.636828\n",
      "Train Epoch: 24 [8960/14140 (63%)]\tLoss: 0.962425\n",
      "Train Epoch: 24 [9600/14140 (68%)]\tLoss: 0.992158\n",
      "Train Epoch: 24 [10240/14140 (72%)]\tLoss: 0.585541\n",
      "Train Epoch: 24 [10880/14140 (77%)]\tLoss: 0.785305\n",
      "Train Epoch: 24 [11520/14140 (81%)]\tLoss: 0.984996\n",
      "Train Epoch: 24 [12160/14140 (86%)]\tLoss: 0.720206\n",
      "Train Epoch: 24 [12800/14140 (90%)]\tLoss: 0.779900\n",
      "Train Epoch: 24 [13440/14140 (95%)]\tLoss: 0.838199\n",
      "Train Epoch: 24 [13200/14140 (100%)]\tLoss: 0.884109\n",
      "Validation Accuracy: 0.4970\n",
      "Test set: Batch 1 of 48 - Loss: 119.3447, Accuracy: 39/3030 (1%)\n",
      "Test set: Batch 2 of 48 - Loss: 96.9700, Accuracy: 80/3030 (3%)\n",
      "Test set: Batch 3 of 48 - Loss: 105.0445, Accuracy: 117/3030 (4%)\n",
      "Test set: Batch 4 of 48 - Loss: 108.7577, Accuracy: 150/3030 (5%)\n",
      "Test set: Batch 5 of 48 - Loss: 114.9114, Accuracy: 186/3030 (6%)\n",
      "Test set: Batch 6 of 48 - Loss: 116.5368, Accuracy: 219/3030 (7%)\n",
      "Test set: Batch 7 of 48 - Loss: 124.8713, Accuracy: 248/3030 (8%)\n",
      "Test set: Batch 8 of 48 - Loss: 126.5876, Accuracy: 282/3030 (9%)\n",
      "Test set: Batch 9 of 48 - Loss: 130.2989, Accuracy: 312/3030 (10%)\n",
      "Test set: Batch 10 of 48 - Loss: 129.8812, Accuracy: 342/3030 (11%)\n",
      "Test set: Batch 11 of 48 - Loss: 129.6681, Accuracy: 376/3030 (12%)\n",
      "Test set: Batch 12 of 48 - Loss: 131.6069, Accuracy: 408/3030 (13%)\n",
      "Test set: Batch 13 of 48 - Loss: 131.6563, Accuracy: 442/3030 (15%)\n",
      "Test set: Batch 14 of 48 - Loss: 132.1417, Accuracy: 475/3030 (16%)\n",
      "Test set: Batch 15 of 48 - Loss: 132.8665, Accuracy: 507/3030 (17%)\n",
      "Test set: Batch 16 of 48 - Loss: 135.5473, Accuracy: 539/3030 (18%)\n",
      "Test set: Batch 17 of 48 - Loss: 137.4311, Accuracy: 564/3030 (19%)\n",
      "Test set: Batch 18 of 48 - Loss: 137.6190, Accuracy: 592/3030 (20%)\n",
      "Test set: Batch 19 of 48 - Loss: 139.5151, Accuracy: 623/3030 (21%)\n",
      "Test set: Batch 20 of 48 - Loss: 138.6179, Accuracy: 660/3030 (22%)\n",
      "Test set: Batch 21 of 48 - Loss: 140.2712, Accuracy: 683/3030 (23%)\n",
      "Test set: Batch 22 of 48 - Loss: 142.8523, Accuracy: 706/3030 (23%)\n",
      "Test set: Batch 23 of 48 - Loss: 142.0916, Accuracy: 744/3030 (25%)\n",
      "Test set: Batch 24 of 48 - Loss: 142.4759, Accuracy: 778/3030 (26%)\n",
      "Test set: Batch 25 of 48 - Loss: 141.4740, Accuracy: 816/3030 (27%)\n",
      "Test set: Batch 26 of 48 - Loss: 141.4320, Accuracy: 848/3030 (28%)\n",
      "Test set: Batch 27 of 48 - Loss: 140.9175, Accuracy: 882/3030 (29%)\n",
      "Test set: Batch 28 of 48 - Loss: 141.9624, Accuracy: 912/3030 (30%)\n",
      "Test set: Batch 29 of 48 - Loss: 141.7049, Accuracy: 947/3030 (31%)\n",
      "Test set: Batch 30 of 48 - Loss: 142.7325, Accuracy: 976/3030 (32%)\n",
      "Test set: Batch 31 of 48 - Loss: 141.0791, Accuracy: 1014/3030 (33%)\n",
      "Test set: Batch 32 of 48 - Loss: 141.6272, Accuracy: 1047/3030 (35%)\n",
      "Test set: Batch 33 of 48 - Loss: 141.2801, Accuracy: 1086/3030 (36%)\n",
      "Test set: Batch 34 of 48 - Loss: 140.9542, Accuracy: 1120/3030 (37%)\n",
      "Test set: Batch 35 of 48 - Loss: 141.5459, Accuracy: 1147/3030 (38%)\n",
      "Test set: Batch 36 of 48 - Loss: 141.0889, Accuracy: 1185/3030 (39%)\n",
      "Test set: Batch 37 of 48 - Loss: 140.9844, Accuracy: 1222/3030 (40%)\n",
      "Test set: Batch 38 of 48 - Loss: 142.6050, Accuracy: 1249/3030 (41%)\n",
      "Test set: Batch 39 of 48 - Loss: 141.9255, Accuracy: 1285/3030 (42%)\n",
      "Test set: Batch 40 of 48 - Loss: 142.0782, Accuracy: 1314/3030 (43%)\n",
      "Test set: Batch 41 of 48 - Loss: 142.3112, Accuracy: 1345/3030 (44%)\n",
      "Test set: Batch 42 of 48 - Loss: 142.0666, Accuracy: 1380/3030 (46%)\n",
      "Test set: Batch 43 of 48 - Loss: 142.1209, Accuracy: 1410/3030 (47%)\n",
      "Test set: Batch 44 of 48 - Loss: 142.6640, Accuracy: 1444/3030 (48%)\n",
      "Test set: Batch 45 of 48 - Loss: 143.1381, Accuracy: 1476/3030 (49%)\n",
      "Test set: Batch 46 of 48 - Loss: 142.7850, Accuracy: 1509/3030 (50%)\n",
      "Test set: Batch 47 of 48 - Loss: 142.5728, Accuracy: 1541/3030 (51%)\n",
      "Test set: Batch 48 of 48 - Loss: 140.8206, Accuracy: 1551/3030 (51%)\n",
      "\n",
      "Test set: Average loss: 2.2308, Accuracy: 1551/3030 (51%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class_names = sorted(set(target for batch in train_loader for target in batch[1]))\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "def test(model, device, test_loader, class_to_idx):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = torch.tensor([class_to_idx[t] for t in target], dtype=torch.long).to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            print(f'Test set: Batch {batch_idx+1} of {len(test_loader)} - Loss: {test_loss/(batch_idx+1):.4f}, '\n",
    "                  f'Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "                  f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "def validate(model, device, val_loader, class_to_idx):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device)\n",
    "            target = torch.tensor([class_to_idx[t] for t in target], dtype=torch.long).to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = total_correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, class_to_idx):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = torch.tensor([class_to_idx[t] for t in target], dtype=torch.long).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(25):\n",
    "    train(model, device, train_loader, optimizer, epoch, class_to_idx)\n",
    "    validate(model, device, val_loader, class_to_idx)\n",
    "    torch.save(model.state_dict(), 'lastepoch_model.pth')\n",
    "\n",
    "test(model, device, test_loader, class_to_idx)\n",
    "torch.save(model.state_dict(), 'tested_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
